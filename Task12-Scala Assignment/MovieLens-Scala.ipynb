{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val movies=spark.read.textFile(\"u.item\")\n",
    "val m_id=movies.map(lines=>lines.split(\"::\")(0)).toDF(\"MovieID\")\n",
    "val m_title=movies.map(lines=>lines.split(\"::\")(1)).toDF(\"Title\")\n",
    "val m_genre=movies.map(lines=>lines.split(\"::\")(2)).toDF(\"Genres\")\n",
    "\n",
    "// For appending the dataframes, we need to import monotonically_increasing_id\n",
    "import org.apache.spark.sql.functions.monotonically_increasing_id\n",
    "val m_res1=m_id.withColumn(\"id\", monotonically_increasing_id()).join(m_title.withColumn(\"id\", monotonically_increasing_id()), Seq(\"id\")).drop(\"id\")\n",
    "val m_result=m_res1.withColumn(\"id\", monotonically_increasing_id()).join(m_genre.withColumn(\"id\", monotonically_increasing_id()), Seq(\"id\")).drop(\"id\")\n",
    "\n",
    "// This will give us the valid data with schema\n",
    "m_result.show\n",
    "\n",
    "// Examples\n",
    "m_result.where(\"MovieID=1\").show\n",
    "m_result.filter(\"Genres == 'Action'\").show\n",
    "m_result.select(\"Title\").show\n",
    "\n",
    "// Will continue\n",
    "System.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 10 movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val ratingsRDD=sc.textFile(\"u.data\")\n",
    "val movies=ratingsRDD.map(line=>line.split(\"::\")(1).toInt)\n",
    "val movies_pair=movies.map(mv=>(mv,1))\n",
    "\n",
    "val movies_count=movies_pair.reduceByKey((x,y)=>x+y)\n",
    "val movies_sorted=movies_count.sortBy(x=>x._2,false,1)\n",
    "\n",
    "val mv_top10List=movies_sorted.take(10).toList\n",
    "val mv_top10RDD=sc.parallelize(mv_top10List)\n",
    "\n",
    "val mv_names=sc.textFile(\"u.item\").map(line=>(line.split(\"::\")(0).toInt,line.split(\"::\")(1)))\n",
    "val join_out=mv_names.join(mv_top10RDD)\n",
    "join_out.sortBy(x=>x._2._2,false).map(x=> x._1+\",\"+x._2._1+\",\"+x._2._2).repartition(1).saveAsTextFile(\"Top-10-CSV\")\n",
    "System.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movies Sorted according to Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val movies_rdd=sc.textFile(\"u.item\")\n",
    "val genre=movies_rdd.map(lines=>lines.split(\"::\")(2))\n",
    "val flat_genre=genre.flatMap(lines=>lines.split(\"\\\\|\"))\n",
    "val genre_kv=flat_genre.map(k=>(k,1))\n",
    "val genre_count=genre_kv.reduceByKey((k,v)=>(k+v))\n",
    "val genre_sort= genre_count.sortByKey()\n",
    "genre_sort.saveAsTextFile(\"result-csv\")\n",
    "System.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIST OF DISTINCT GENRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "val movies_rdd=sc.textFile(\"u.item\")\n",
    "val genres=movies_rdd.map(lines=>lines.split(\"::\")(2))\n",
    "val testing=genres.flatMap(line=>line.split('|'))\n",
    "val genres_distinct_sorted=testing.distinct().sortBy(_(0))\n",
    "genres_distinct_sorted.saveAsTextFile(\"result\")\n",
    "System.exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of Oldest Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "val movies_rdd=sc.textFile(\"u.item\")\n",
    "// 1st method, convert existing rdd into DF using toDF function and then make it into a view\n",
    "val movies_DF=movies_rdd.toDF.createOrReplaceTempView(\"movies_view\")\n",
    "// To use spark.sql, it should be at least a temporary view or even an table\n",
    "spark.sql(\"\"\" select\n",
    "split(value,'::')[0] as movieid,\n",
    "split(value,'::')[1] as moviename,\n",
    "substring(split(value,'::')[1],length(split(value,'::')[1])-4,4) as year\n",
    "from movies_view \"\"\").createOrReplaceTempView(\"movies\");\n",
    "// To view the records, use spark.sql(\"select * from movies\").show()\n",
    "var result=spark.sql(\"Select * from movies m1 where m1.year=(Select min(m2.year) from movies m2)\").repartition(1).rdd.saveAsTextFile(\"result\")\n",
    "System.exit(0);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
